{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import wabt\n",
    "\n",
    "importlib.reload(wabt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from river import stream\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from wabt import WeightAdjustingBinaryTransformation\n",
    "from utils import get_dataset, compute_metrics_dataset_online\n",
    "import nemenyi\n",
    "import numpy as np\n",
    "from river import multioutput\n",
    "from river import tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# For verifying that the datasets can be loaded:\n",
    "n_labels, X, Y = get_dataset('Corel5k.arff')\n",
    "print(X[0])\n",
    "print(Y[0])\n",
    "print(n_labels)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def add_feature_noise(x, noise_level=0.1):\n",
    "    noisy_x = {}\n",
    "    for k, v in x.items():\n",
    "        if isinstance(v, (int, float)):\n",
    "            v += np.random.normal(0, noise_level)\n",
    "        noisy_x[k] = v\n",
    "    return noisy_x\n",
    "\n",
    "def test_model_on_ds(model_class, dataset, noise=False):\n",
    "    n_labels, X, Y = get_dataset(dataset)\n",
    "\n",
    "    if model_class == multioutput.ClassifierChain:\n",
    "        model = multioutput.ClassifierChain(model=tree.HoeffdingTreeClassifier(), order=list(range(n_labels)))\n",
    "    elif model_class == multioutput.MultiClassEncoder:\n",
    "        model = multioutput.MultiClassEncoder(model=tree.HoeffdingTreeClassifier())\n",
    "    else:\n",
    "        model = model_class(n_labels=n_labels)\n",
    "\n",
    "    if model_class == multioutput.ClassifierChain or model_class == multioutput.MultiClassEncoder:\n",
    "        # Init with empty vectors to avoid issues with unseen labels during the first prediction\n",
    "        ds_temp = stream.iter_array(X, Y)\n",
    "        x_first, y_first = next(iter(ds_temp))\n",
    "\n",
    "        dummy_x = {k: 0 for k in x_first.keys()}\n",
    "        dummy_y = {k: 0 for k in y_first.keys()}\n",
    "\n",
    "        # Train the model with dummy data\n",
    "        model.learn_one(dummy_x, dummy_y)\n",
    "\n",
    "    ds = stream.iter_array(X, Y)\n",
    "\n",
    "    y_true_arr = []\n",
    "    y_pred_arr = []\n",
    "\n",
    "    pbar = tqdm(total=len(X))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for step, (x, y) in enumerate(ds):\n",
    "        if noise:\n",
    "            x = add_feature_noise(x, noise_level=1)\n",
    "\n",
    "        y_pred = model.predict_one(x)\n",
    "        model.learn_one(x, y)\n",
    "\n",
    "        y_true_arr.append(list(y.values()))\n",
    "\n",
    "        if model_class == multioutput.ClassifierChain or model_class == multioutput.MultiClassEncoder:\n",
    "            y_pred_arr.append(np.array(list(y_pred.values()), dtype=int))\n",
    "        else:\n",
    "            y_pred_arr.append(y_pred.astype(int))\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Plotting weights for WABT\n",
    "    if model_class == WeightAdjustingBinaryTransformation:\n",
    "        model.plot_weight_history(str(dataset)[:-5],skip = 10, top_n=5)\n",
    "\n",
    "    print(str(dataset) + \" processed in \" + str((time.time() - start_time)) + \" seconds.\")\n",
    "    pbar.close()\n",
    "\n",
    "    results = compute_metrics_dataset_online(y_true_arr, y_pred_arr)\n",
    "    print(\"Acc: \" + \"{:.3f} \".format(results[\"accuracy\"]) + \", \" + \"Hamming Score: \" + \"{:.3f} \".format(\n",
    "        results[\"hamming_score\"]))\n",
    "    print(\"Micro-F1: \" + \"{:.3f} \".format(results[\"micro-f1\"]) + \", \" + \"Example-based F1: \" + \"{:.3f} \".format(\n",
    "        results[\"f1_score\"]))\n",
    "\n",
    "    # Change the results file if needed\n",
    "    results_file = \"./results/experiment_results.txt\"\n",
    "\n",
    "    result_str = (f\"Dataset: {dataset}, Model: {model_class.__name__}, \"\n",
    "                  f\"Noise: {noise}, \"\n",
    "                  f\"Acc: {results['accuracy']:.3f}, \"\n",
    "                  f\"Hamming: {results['hamming_score']:.3f}, \"\n",
    "                  f\"Micro-F1: {results['micro-f1']:.3f}, \"\n",
    "                  f\"Example-F1: {results['f1_score']:.3f}\\n\")\n",
    "\n",
    "    with open(results_file, \"a\") as f:\n",
    "        f.write(result_str)\n",
    "\n",
    "    print(f\"Results appended to {results_file}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Reuters.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Corel5k.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Corel16k.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'langlog.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Stackex_cs.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Stackex_cooking.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Stackex-chemistry.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Stackex_philosophy.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Slashdot.arff', noise=False)\n",
    "test_model_on_ds(WeightAdjustingBinaryTransformation, 'Yelp.arff', noise=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "nemenyi.nemenyi_test_and_plot(\"./results/hamming.csv\", ascending=False, save_plot=True)",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
